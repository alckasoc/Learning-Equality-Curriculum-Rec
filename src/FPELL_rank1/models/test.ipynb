{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d5efcd0-2680-4af7-8c7c-309844ea30b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "55278d7e-7bf5-4b54-9c5b-b5762314fec6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from transformers import AutoModel, AutoConfig\n",
    "from pooling import *\n",
    "\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, model, pooling_type, hidden_size=None, config_path=None, pretrained=False):\n",
    "        super().__init__()\n",
    "        self.pooling_type = pooling_type\n",
    "        \n",
    "        if config_path is None:\n",
    "            self.config = AutoConfig.from_pretrained(model, output_hidden_states=True)\n",
    "            self.config.hidden_dropout = 0.\n",
    "            self.config.hidden_dropout_prob = 0.\n",
    "            self.config.attention_dropout = 0.\n",
    "            self.config.attention_probs_dropout_prob = 0.\n",
    "            self.config.hidden_size = 384\n",
    "        else:\n",
    "            self.config = torch.load(config_path)\n",
    "            \n",
    "        if pretrained:\n",
    "            self.backbone = AutoModel.from_pretrained(model, config=self.config)\n",
    "        else:\n",
    "            self.backbone = AutoModel.from_config(self.config)\n",
    "        \n",
    "        if pooling_type == 'MeanPooling':\n",
    "            self.pool = MeanPooling()\n",
    "        elif pooling_type == 'WeightedLayerPooling':\n",
    "            self.pool = WeightedLayerPooling(self.config.num_hidden_layers)\n",
    "        elif pooling_type == 'LSTMPooling':\n",
    "            self.pool =  LSTMPooling(self.config.num_hidden_layers,\n",
    "                                       self.config.hidden_size,\n",
    "                                       hidden_size,\n",
    "                                       0.1,\n",
    "                                       is_lstm=True\n",
    "                           )\n",
    "        else:\n",
    "            raise ValueError('Unknown pooling type')\n",
    "        \n",
    "        \n",
    "        if pooling_type == 'GRUPooling':\n",
    "            self.fc = nn.Linear(hidden_size, 6)\n",
    "        elif pooling_type == 'LSTMPooling':\n",
    "            self.fc = nn.Linear(hidden_size, 6)\n",
    "        else:\n",
    "            self.fc = nn.Linear(self.config.hidden_size, 6)\n",
    "        \n",
    "    def feature(self, inputs):\n",
    "        outputs = self.backbone(**inputs)\n",
    "        \n",
    "        last_hidden_states = outputs[0]\n",
    "        \n",
    "        if self.pooling_type == 'MeanPooling':\n",
    "            feature = self.pool(last_hidden_states, inputs['attention_mask'])\n",
    "        elif self.pooling_type == 'WeightedLayerPooling':\n",
    "            all_hidden_states = torch.stack(outputs[1])\n",
    "            feature = self.pool(all_hidden_states)\n",
    "        elif self.pooling_type in ['GRUPooling', 'LSTMPooling']:\n",
    "            all_hidden_states = torch.stack(outputs[1])\n",
    "            feature = self.pool(all_hidden_states)\n",
    "        else:\n",
    "            raise ValueError('Unknown pooling type')\n",
    "        \n",
    "        return outputs, feature\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        original_outputs, feature = self.feature(inputs)\n",
    "        output = self.fc(feature)\n",
    "        return feature, original_outputs, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f785e21a-29d9-4be6-8294-3f28209df791",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be51bec5ff2b4e489f2fb01e2c43d935",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)lve/main/config.json:   0%|          | 0.00/580 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "m1 = CustomModel(\"microsoft/deberta-v3-large\", \"MeanPooling\", hidden_size=None, config_path=\"../../../input/model23/config.pth\", pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8a2cf209-98dd-4546-a5ba-3707474c08fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DebertaV2Config {\n",
       "  \"_name_or_path\": \"microsoft/deberta-v3-large\",\n",
       "  \"attention_dropout\": 0.0,\n",
       "  \"attention_probs_dropout_prob\": 0.0,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout\": 0.0,\n",
       "  \"hidden_dropout_prob\": 0.0,\n",
       "  \"hidden_size\": 384,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 4096,\n",
       "  \"layer_norm_eps\": 1e-07,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"max_relative_positions\": -1,\n",
       "  \"model_type\": \"deberta-v2\",\n",
       "  \"norm_rel_ebd\": \"layer_norm\",\n",
       "  \"num_attention_heads\": 16,\n",
       "  \"num_hidden_layers\": 24,\n",
       "  \"output_hidden_states\": true,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"pooler_dropout\": 0,\n",
       "  \"pooler_hidden_act\": \"gelu\",\n",
       "  \"pooler_hidden_size\": 1024,\n",
       "  \"pos_att_type\": [\n",
       "    \"p2c\",\n",
       "    \"c2p\"\n",
       "  ],\n",
       "  \"position_biased_input\": false,\n",
       "  \"position_buckets\": 256,\n",
       "  \"relative_attention\": true,\n",
       "  \"share_att_key\": true,\n",
       "  \"transformers_version\": \"4.26.1\",\n",
       "  \"type_vocab_size\": 0,\n",
       "  \"vocab_size\": 128100\n",
       "}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4698bd65-c573-4c9c-91ca-7573c47c0ade",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MultipleNegativesRankingLoss(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.loss_function = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, embeddings_a, embeddings_b, labels=None):\n",
    "        \"\"\"\n",
    "        Compute similarity between a and b.\n",
    "        Labels have the index of the row number at each row. \n",
    "        This indicates that a_i and b_j have high similarity \n",
    "        when i==j and low similarity when i!=j.\n",
    "        \"\"\"\n",
    "\n",
    "        similarity_scores = (\n",
    "            cos_sim(embeddings_a, embeddings_b) * 20.0\n",
    "        )  # Not too sure why to scale it by 20: https://github.com/UKPLab/sentence-transformers/blob/b86eec31cf0a102ad786ba1ff31bfeb4998d3ca5/sentence_transformers/losses/MultipleNegativesRankingLoss.py#L57\n",
    "\n",
    "        print(similarity_scores)\n",
    "        \n",
    "        labels = torch.tensor(\n",
    "            range(len(similarity_scores)),\n",
    "            dtype=torch.long,\n",
    "            device=similarity_scores.device,\n",
    "        )  # Example a[i] should match with b[i]\n",
    "\n",
    "        print(labels)\n",
    "        \n",
    "        return self.loss_function(similarity_scores, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f40b34f0-e983-4f09-b437-1ff95c89dc1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss = MultipleNegativesRankingLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6c487ca2-c896-43fe-838d-52c7c4de8e34",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CrossEntropyLoss()"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.loss_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c3495d1e-9ca0-424b-a559-9fff2653b9df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cos_sim(a, b):\n",
    "    # From https://github.com/UKPLab/sentence-transformers/blob/master/sentence_transformers/util.py#L31\n",
    "    \"\"\"\n",
    "    Computes the cosine similarity cos_sim(a[i], b[j]) for all i and j.\n",
    "    :return: Matrix with res[i][j]  = cos_sim(a[i], b[j])\n",
    "    \"\"\"\n",
    "    if not isinstance(a, torch.Tensor):\n",
    "        a = torch.tensor(a)\n",
    "\n",
    "    if not isinstance(b, torch.Tensor):\n",
    "        b = torch.tensor(b)\n",
    "\n",
    "    if len(a.shape) == 1:\n",
    "        a = a.unsqueeze(0)\n",
    "\n",
    "    if len(b.shape) == 1:\n",
    "        b = b.unsqueeze(0)\n",
    "\n",
    "    a_norm = torch.nn.functional.normalize(a, p=2, dim=1)\n",
    "    b_norm = torch.nn.functional.normalize(b, p=2, dim=1)\n",
    "    return torch.mm(a_norm, b_norm.transpose(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "16dab901-aa1a-472b-a724-7f2c633672e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "m1.fc = nn.Linear(in_features=384, out_features=1, bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "646012c6-cd1e-40a4-b2e1-992cc65154cd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1.config.hidden_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2345b1d9-b82b-4e6f-b520-a22b0808c9dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a = torch.load(\"../../../input/pseudo_label/out_features_m1.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad7bfb2b-5939-41c1-bd82-45f6d300db1c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([615170, 384])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3ca73b6b-c6c6-46eb-9156-d74ecf3af776",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3803]])\n",
      "tensor([0])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(f.view(-1), a[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "11316177-f017-4a64-b22b-4282727f7c81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f.view(-1)\n",
    "ff = torch.concat([f, f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b5655b49-7c22-4575-a921-19ccf6fc9eb3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.5083, -0.2483],\n",
      "        [ 0.5083, -0.2483]])\n",
      "tensor([0, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.7631)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(ff, a[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "174e64a9-d6db-4ad8-a7ae-1733b15e894d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "b = torch.load(\"../../../input/pseudo_label/preds_m1.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "df466682-5c67-4b9b-b22c-78aa503e4819",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(36527)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(torch.sigmoid(b) > 0.1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a454fafc-f4d6-49ea-9a2c-19328ea38642",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(62415)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = torch.load(\"../../../input/pseudo_label/preds_m2.pt\")\n",
    "(torch.sigmoid(c) > 0.3).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "6c78679c-7347-4723-a1b5-4ee54fc38545",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        ...,\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.logical_or(b, c).to(torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1f400c0e-11ea-4c4d-b753-59920094617f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "d = torch.load(\"../../../input/pseudo_label/out_features_m1.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "10760d51-de43-4084-a68e-20b92e78dc77",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([615170, 384])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "481de828-adbd-445d-b780-a10082f47e94",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-3.9392e-01, -3.6166e-01, -3.7874e-01,  1.0420e-01,  2.7154e-01,\n",
       "        -2.9612e-01, -5.7274e-01,  5.7165e-01,  7.1899e-01, -5.6558e-01,\n",
       "        -4.0695e-01,  9.0580e-01,  5.7599e-01,  4.0355e-01,  3.2290e-01,\n",
       "        -9.8855e-02, -6.9699e-01, -3.8754e-01,  2.5195e-01,  4.9964e-01,\n",
       "         7.5651e-02,  6.5373e-02,  2.4497e-01, -5.8589e-01, -9.2474e-01,\n",
       "        -6.5252e-01, -7.8153e-02, -5.0431e-01,  3.4163e-01,  3.3922e-01,\n",
       "         2.5057e-01,  6.3353e-01,  3.5714e-01, -2.9381e-01,  2.7550e-01,\n",
       "        -3.6158e-02,  1.9560e-01,  6.8414e-02, -6.3210e-01,  2.2098e-01,\n",
       "         3.1501e-01,  7.5646e-02,  3.8383e-01,  8.2166e-01, -2.8584e-01,\n",
       "        -2.9226e-01, -7.1935e-01, -4.1117e-01,  4.8832e-01,  9.3107e-02,\n",
       "         1.8719e-01,  9.3699e-02,  1.3574e-01,  3.4655e-01,  3.3137e-01,\n",
       "        -2.9463e-01,  1.7813e-01, -3.2290e-01, -3.1104e-01, -7.0018e-01,\n",
       "        -6.6927e-01, -5.0627e-01, -4.9122e-01, -1.4243e-01,  3.5948e-01,\n",
       "         4.7512e-01,  2.0355e-01,  4.2848e-01,  2.6889e-01, -6.8605e-01,\n",
       "         9.1539e-02,  9.5979e-01,  3.1117e-01,  1.1199e-01, -2.0468e-01,\n",
       "         1.8065e-01,  9.8517e-02,  1.8147e-01,  7.7449e-01, -7.4851e-02,\n",
       "        -1.0900e+00,  9.1740e-02,  4.2847e-01, -2.9175e-01, -1.3508e-01,\n",
       "         3.8434e-01,  6.8675e-01, -4.2470e-01, -3.3795e-01, -5.1364e-01,\n",
       "         1.4717e-01, -2.5898e-01,  1.4822e-01,  2.4953e-01, -8.0353e-01,\n",
       "        -2.6123e-01,  7.1245e-01,  2.0320e-01,  2.5028e-01, -1.1811e-02,\n",
       "        -5.2471e-01,  4.6836e-01,  2.4307e-01,  8.8427e-01,  3.0280e-01,\n",
       "         4.6452e-01, -7.1762e-01,  1.2820e-01,  2.0803e-01,  4.4744e-01,\n",
       "         5.7494e-01, -6.8611e-01,  9.0107e-01,  1.6957e-01, -6.3555e-01,\n",
       "        -1.9732e-02, -7.8353e-01, -7.3695e-01, -1.0646e-01, -4.4372e-01,\n",
       "         7.1407e-01,  7.9421e-01, -5.3279e-01,  1.1419e+00, -5.9666e-01,\n",
       "         2.9366e-02,  6.2807e-01, -9.1241e-03, -8.7015e-01,  5.9449e-01,\n",
       "         2.7680e-01,  4.2865e-02, -2.0774e-01,  1.3723e-01, -1.8661e-01,\n",
       "        -1.2052e-01,  1.4348e-01,  2.5238e-01, -1.0282e-01,  1.6951e-01,\n",
       "         1.1455e-01,  2.1975e-01,  1.1929e+00, -2.6057e-01, -4.4131e-01,\n",
       "         3.5663e-01,  4.2414e-01, -1.6080e-01,  4.2771e-01,  2.8018e-01,\n",
       "         3.0444e-01,  3.6266e-01, -1.2507e-02, -3.4642e-01,  1.0784e-02,\n",
       "         5.5414e-02, -3.7941e-01, -2.1508e-01, -3.7692e-02,  7.9755e-02,\n",
       "         4.8673e-01,  5.2775e-01,  1.1091e-01, -8.0776e-03,  3.7283e-01,\n",
       "        -4.5711e-02,  3.2531e-01, -4.1585e-01,  4.1687e-01,  1.8741e-01,\n",
       "         4.2498e-01,  2.1452e-01,  3.2458e-02, -9.9949e-02,  5.5192e-01,\n",
       "        -7.2666e-01,  1.1050e-01,  1.1554e-01, -1.7226e-01,  4.0259e-01,\n",
       "         2.7677e-01, -8.1289e-01,  1.4397e-01,  3.9306e-01,  9.9359e-01,\n",
       "        -1.2725e-01, -4.2434e-01, -3.5865e-01, -8.6846e-02,  5.4818e-03,\n",
       "        -4.8730e-01,  5.8221e-01,  5.7455e-02, -2.1892e-01, -5.9089e-01,\n",
       "         9.7437e-03, -1.0275e-01, -1.1795e-01,  1.7301e-01, -6.1252e-01,\n",
       "         3.3835e-01, -2.1083e-01,  3.3669e-01, -1.1520e-01,  7.7939e-02,\n",
       "        -5.2571e-01, -3.8916e-01,  1.2985e-01, -9.0953e-01,  7.4265e-01,\n",
       "         6.9661e-03,  4.3525e-03,  4.2567e-01,  1.8802e-01, -6.2989e-02,\n",
       "         3.6672e-01,  5.8021e-01,  5.5476e-01, -2.4854e-01, -1.0399e-01,\n",
       "        -7.7877e-01,  6.1970e-01, -4.1473e-01, -7.4640e-04, -1.0047e-01,\n",
       "        -2.8178e-01, -8.8754e-03,  2.7258e-01,  1.8045e-02,  5.6077e-01,\n",
       "         2.6231e-01,  3.5843e-01, -1.8568e-01,  2.8211e-01, -7.5714e-02,\n",
       "         8.3637e-01, -3.1092e-03, -7.1391e-01,  8.2437e-02,  5.7301e-01,\n",
       "        -5.1194e-01,  6.7166e-02, -8.0370e-02, -5.8723e-01,  3.0672e-01,\n",
       "         3.7834e-01, -8.0243e-01,  4.0937e-01, -3.1848e-01,  1.5875e-01,\n",
       "        -1.5553e-03, -6.2015e-02,  5.0684e-01,  1.9606e-02, -9.4689e-01,\n",
       "         9.0979e-02,  2.7490e-01, -2.4405e-01, -1.7955e-01, -7.1768e-02,\n",
       "        -3.9441e-01, -6.9383e-01,  3.0596e-01,  6.3660e-01,  2.1069e-02,\n",
       "        -1.4209e+00,  1.6171e-01, -2.2076e-01,  4.5642e-01, -6.5468e-01,\n",
       "         3.3258e-01,  1.4267e-01,  3.7329e-01,  1.2990e-01,  2.0952e-01,\n",
       "         2.2183e-01,  7.5231e-01, -4.8128e-02, -5.5848e-02,  3.1016e-01,\n",
       "        -2.3039e-01, -2.9462e-01,  4.3802e-01, -4.0099e-01,  2.2186e-01,\n",
       "         1.1175e-01, -2.3729e-02,  1.5630e-01,  1.7851e-01, -3.5713e-01,\n",
       "         3.7664e-01,  1.1372e-01, -9.1582e-02, -2.0005e-01,  7.2932e-01,\n",
       "         2.2569e-01, -3.9450e-02, -1.1455e-01, -4.5006e-01, -5.4739e-02,\n",
       "        -5.0910e-01,  6.9283e-02,  3.3141e-02,  3.7731e-01, -2.5583e-01,\n",
       "         5.8090e-01,  5.3987e-01,  2.0163e-02,  2.9188e-01, -1.1643e-01,\n",
       "         7.1098e-01,  1.6847e-01,  2.3736e-01,  1.5930e-01, -1.0038e+00,\n",
       "         1.2515e-01, -8.1032e-03, -1.9703e-01,  5.4661e-01,  1.0670e-02,\n",
       "        -4.3831e-01,  3.2850e-01,  5.6901e-01,  3.6348e-01,  9.5816e-02,\n",
       "        -3.4517e-01,  6.5594e-01,  4.6410e-01,  2.7635e-01,  4.6673e-01,\n",
       "         2.2282e-01, -1.6418e-01,  7.9670e-01,  5.6507e-02,  7.4897e-01,\n",
       "         2.2577e-01,  3.8362e-01,  5.0250e-02,  2.6953e-02, -1.6552e-01,\n",
       "         1.7004e-01,  3.7591e-01,  3.4849e-01, -8.1227e-01, -5.0234e-01,\n",
       "         2.1423e-01,  5.6016e-01,  3.8876e-01, -2.3156e-01,  1.1905e-01,\n",
       "        -3.7001e-01,  8.6965e-02, -4.4399e-01,  8.5885e-02, -4.3691e-01,\n",
       "        -2.0255e-01, -7.0557e-01,  2.1390e-02, -2.1259e-01, -7.2472e-01,\n",
       "        -2.8267e-01, -1.4961e-01, -2.0533e-01, -2.3806e-01,  5.6943e-01,\n",
       "        -1.6500e-02, -6.3909e-01, -1.5641e-01, -6.8532e-01, -5.1893e-02,\n",
       "         6.2626e-02,  3.4892e-01,  1.4376e-01, -4.5724e-01, -1.9030e-01,\n",
       "        -3.9869e-01,  2.2661e-01,  5.6436e-01, -4.9025e-01, -6.8580e-02,\n",
       "         3.5480e-01,  1.7123e-01,  1.8317e-01,  3.4713e-01])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e627d32f-97bb-43f7-87c5-b78b78b69a9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"../../../input/prep_cleaned_train_context_5fold.csv\", lineterminator=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "cb346e3b-36cd-4017-8c7f-fc5b72134db1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['topics_ids', 'content_ids', 'channel', 'topic_title',\n",
       "       'topic_description', 'topic_parent_title', 'topic_parent_description',\n",
       "       'topic_child_title', 'topic_child_description', 'topic_category',\n",
       "       'topic_language', 'content_title', 'content_description',\n",
       "       'content_text', 'content_kind', 'content_language', 'target',\n",
       "       'topic_fold', 'content_fold', 'text'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c56f8405-b968-4149-9477-b1d953b4d21b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    555239\n",
       "1     59931\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "083b1e01-29bf-493a-be38-779ddf1e0fc5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = ({'input_ids': torch.Tensor([[    0, 48962, 14602,   959, 32316,  1065,   294, 21290,   268, 16734,\n",
    "         17991, 14602,   959, 32316,     2,     1,     1,     1,     1,     1,\n",
    "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
    "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
    "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
    "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
    "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
    "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
    "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
    "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
    "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
    "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
    "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
    "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
    "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
    "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
    "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
    "             1,     1]]).to(torch.int32), 'attention_mask': torch.Tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0]]).to(torch.int32)},\n",
    " torch.Tensor([0.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cc7b1516-5848-4ad4-bfdb-0eaa1339819e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'input_ids': tensor([[    0, 48962, 14602,   959, 32316,  1065,   294, 21290,   268, 16734,\n",
       "           17991, 14602,   959, 32316,     2,     1,     1,     1,     1,     1,\n",
       "               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "               1,     1]], dtype=torch.int32),\n",
       "  'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0]], dtype=torch.int32)},\n",
       " tensor([0.]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c6a95723-4e9f-490d-92de-6a73f30d1c96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "_ = m1.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    f, o, z = m1(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3610df3-bb7e-4fe0-b560-4052f10aef8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 384]), torch.Size([1, 172, 384]), torch.Size([1, 1]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.shape, o.last_hidden_state.shape, z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de4d00b2-e838-4900-b0e7-df1eadee564e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2489]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2bbeac7-0da2-4f90-b438-f4dbb8551673",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['attentions',\n",
       " 'clear',\n",
       " 'copy',\n",
       " 'fromkeys',\n",
       " 'get',\n",
       " 'hidden_states',\n",
       " 'items',\n",
       " 'keys',\n",
       " 'last_hidden_state',\n",
       " 'move_to_end',\n",
       " 'pop',\n",
       " 'popitem',\n",
       " 'setdefault',\n",
       " 'to_tuple',\n",
       " 'update',\n",
       " 'values']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in dir(o) if \"__\" not in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33afd827-e216-4a2e-87d1-418cf6e2c8be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0628, -0.6051, -0.4633,  ..., -1.6161,  0.3332, -0.7899],\n",
       "         [-0.1748, -0.9188, -0.5154,  ..., -1.0968,  0.7967, -0.9400],\n",
       "         [-0.0848, -1.0519, -0.4905,  ..., -1.3074,  0.2581, -0.5332],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bdabbb6d-7884-4625-962f-f22098ce3bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = m1.pool(o[0], x[0]['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89e69d14-6729-4e2a-ac26-0f4d97f071c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1024])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e60db297-d2e8-44fd-96f0-47ebf5ba95bd",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "forward() missing 2 required positional arguments: 'embeddings_a' and 'embeddings_b'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2441/1170416162.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/envs/python37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: forward() missing 2 required positional arguments: 'embeddings_a' and 'embeddings_b'"
     ]
    }
   ],
   "source": [
    "loss(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c4ccf766-3522-4a1b-9377-415092dc1d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoModel, AutoConfig\n",
    "from torch.utils.checkpoint import checkpoint\n",
    "from utils import get_backbone_config\n",
    "\n",
    "def get_last_hidden_state(backbone_outputs):\n",
    "    last_hidden_state = backbone_outputs[0]\n",
    "    return last_hidden_state\n",
    "\n",
    "\n",
    "def get_all_hidden_states(backbone_outputs):\n",
    "    all_hidden_states = torch.stack(backbone_outputs[1])\n",
    "    return all_hidden_states\n",
    "\n",
    "\n",
    "def get_input_ids(inputs):\n",
    "    return inputs['input_ids']\n",
    "\n",
    "\n",
    "def get_attention_mask(inputs):\n",
    "    return inputs['attention_mask']\n",
    "\n",
    "class MeanPooling(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MeanPooling, self).__init__()\n",
    "        self.output_dim = 1024\n",
    "\n",
    "    def forward(self, inputs, backbone_outputs):  # x, o\n",
    "        attention_mask = get_attention_mask(inputs)\n",
    "        last_hidden_state = get_last_hidden_state(backbone_outputs)\n",
    "\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n",
    "        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n",
    "        sum_mask = input_mask_expanded.sum(1)\n",
    "        sum_mask = torch.clamp(sum_mask, min=1e-9)\n",
    "        mean_embeddings = sum_embeddings / sum_mask\n",
    "        return mean_embeddings\n",
    "\n",
    "class custom_model(nn.Module):\n",
    "    def __init__(self, tokenizer, backbone_type):\n",
    "        super().__init__()\n",
    "        self.tokenizer = tokenizer\n",
    "        \n",
    "        if True:\n",
    "            self.backbone_config = get_backbone_config(backbone_type)\n",
    "            self.backbone = AutoModel.from_pretrained(backbone_type, config=self.backbone_config)\n",
    "        else:\n",
    "            self.backbone = AutoModel.from_config(self.backbone_config)\n",
    "\n",
    "        # What is this?\n",
    "        self.backbone.resize_token_embeddings(len(self.tokenizer))\n",
    "        \n",
    "        a = len(self.tokenizer) == self.backbone_config.vocab_size\n",
    "        print(f\"len tokenizer vs backbone config vocab size: {a}\")\n",
    "        \n",
    "        self.pool = MeanPooling()\n",
    "        self.fc = nn.Linear(self.pool.output_dim, 6)\n",
    "\n",
    "#         self._init_weights(self.fc)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        outputs = self.backbone(**inputs)\n",
    "        \n",
    "        feature = self.pool(inputs, outputs)\n",
    "        output = self.fc(feature)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4c523ea-d954-403f-bdb5-2c5e66147490",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "def get_additional_special_tokens():\n",
    "    special_tokens_replacement = {\n",
    "        '\\n': '[BR]',\n",
    "        'Generic_School': '[GENERIC_SCHOOL]',\n",
    "        'Generic_school': '[GENERIC_SCHOOL]',\n",
    "        'SCHOOL_NAME': '[SCHOOL_NAME]',\n",
    "        'STUDENT_NAME': '[STUDENT_NAME]',\n",
    "        'Generic_Name': '[GENERIC_NAME]',\n",
    "        'Genric_Name': '[GENERIC_NAME]',\n",
    "        'Generic_City': '[GENERIC_CITY]',\n",
    "        'LOCATION_NAME': '[LOCATION_NAME]',\n",
    "        'HOTEL_NAME': '[HOTEL_NAME]',\n",
    "        'LANGUAGE_NAME': '[LANGUAGE_NAME]',\n",
    "        'PROPER_NAME': '[PROPER_NAME]',\n",
    "        'OTHER_NAME': '[OTHER_NAME]',\n",
    "        'PROEPR_NAME': '[PROPER_NAME]',\n",
    "        'RESTAURANT_NAME': '[RESTAURANT_NAME]',\n",
    "        'STORE_NAME': '[STORE_NAME]',\n",
    "        'TEACHER_NAME': '[TEACHER_NAME]',\n",
    "    }\n",
    "    return special_tokens_replacement\n",
    "\n",
    "special_tokens_replacement = get_additional_special_tokens()\n",
    "all_special_tokens = list(special_tokens_replacement.values())\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/deberta-v3-large\",\n",
    "                                      use_fast=True,\n",
    "                                      additional_special_tokens=all_special_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06e4a76b-b896-48c6-aa9d-c8b6a9cbff60",
   "metadata": {},
   "outputs": [],
   "source": [
    "special_tokens_replacement = {\n",
    "    '\\n': '[BR]',\n",
    "    'Generic_School': '[GENERIC_SCHOOL]',\n",
    "    'Generic_school': '[GENERIC_SCHOOL]',\n",
    "    'SCHOOL_NAME': '[SCHOOL_NAME]',\n",
    "    'STUDENT_NAME': '[STUDENT_NAME]',\n",
    "    'Generic_Name': '[GENERIC_NAME]',\n",
    "    'Genric_Name': '[GENERIC_NAME]',\n",
    "    'Generic_City': '[GENERIC_CITY]',\n",
    "    'LOCATION_NAME': '[LOCATION_NAME]',\n",
    "    'HOTEL_NAME': '[HOTEL_NAME]',\n",
    "    'LANGUAGE_NAME': '[LANGUAGE_NAME]',\n",
    "    'PROPER_NAME': '[PROPER_NAME]',\n",
    "    'OTHER_NAME': '[OTHER_NAME]',\n",
    "    'PROEPR_NAME': '[PROPER_NAME]',\n",
    "    'RESTAURANT_NAME': '[RESTAURANT_NAME]',\n",
    "    'STORE_NAME': '[STORE_NAME]',\n",
    "    'TEACHER_NAME': '[TEACHER_NAME]',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a729a52d-c966-4c33-b4de-02f6b919019b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len((list(special_tokens_replacement.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c69ac787-dcee-4ae4-b3e6-feac2ff61f0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DebertaV2TokenizerFast(name_or_path='microsoft/deberta-v3-large', vocab_size=128000, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '[CLS]', 'eos_token': '[SEP]', 'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]', 'additional_special_tokens': ['[BR]', '[GENERIC_SCHOOL]', '[GENERIC_SCHOOL]', '[SCHOOL_NAME]', '[STUDENT_NAME]', '[GENERIC_NAME]', '[GENERIC_NAME]', '[GENERIC_CITY]', '[LOCATION_NAME]', '[HOTEL_NAME]', '[LANGUAGE_NAME]', '[PROPER_NAME]', '[OTHER_NAME]', '[PROPER_NAME]', '[RESTAURANT_NAME]', '[STORE_NAME]', '[TEACHER_NAME]']})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1d74352c-f487-403e-ab33-b7b9f2d037e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.LayerNorm.bias', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.classifier.weight', 'mask_predictions.dense.weight', 'mask_predictions.dense.bias', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.bias']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len tokenizer vs backbone config vocab size: True\n"
     ]
    }
   ],
   "source": [
    "m2 = custom_model(tokenizer, \"microsoft/deberta-v3-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9f2bcc53-f57f-482d-9d70-68c8224e3468",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128015"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2.backbone_config.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3f843970-5cf6-41b7-b1d3-0f496c10aa46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "C:\\Users\\alcka\\anaconda3\\lib\\site-packages\\transformers\\convert_slow_tokenizer.py:446: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "t = AutoTokenizer.from_pretrained(\"microsoft/deberta-v3-large\",\n",
    "                                      use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "928b64fd-6009-43ae-85d4-32632f227b22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DebertaV2TokenizerFast(name_or_path='microsoft/deberta-v3-large', vocab_size=128000, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '[CLS]', 'eos_token': '[SEP]', 'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ec2ea69e-37ef-4598-ac76-b191f3b69cf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128015"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d624dbe3-a6ae-4824-b064-2728edb128ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128001"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "adeb3344-a9e6-4a8e-8328-a59644c468bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2.load_state_dict(m1.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0dbc9729-405c-4a7a-a0d2-2ab1bbf6a7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = m2.eval()\n",
    "with torch.no_grad():\n",
    "    z = m2(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aeda0770-a692-4c35-a248-5a4577efc1ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0079,  0.0859, -0.3627, -1.0221,  0.6245,  0.0832]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56532c73-d28f-457e-b845-26c2d7b18aaf",
   "metadata": {},
   "source": [
    "tensor([[ 0.0079,  0.0859, -0.3627, -1.0221,  0.6245,  0.0832]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0b5221b3-2aa8-4c49-bcd9-71da2cc42f73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0575, -1.1382, -0.3632,  ..., -1.5897,  0.6908, -0.3918]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19df2ae-2885-49aa-b0e7-9080b1b84310",
   "metadata": {},
   "source": [
    "m1.pool(o, x[0]['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "41cab033-bacb-4506-ad2d-5032004496d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_ = m2.pool(x[0], o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ecaefefe-fcc2-4734-aa00-43ce432cd78a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1024)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(feature_ == feature).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4a412369-b967-4af9-8141-46946c9af121",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = AutoConfig.from_pretrained(\"microsoft/deberta-v3-large\", output_hidden_states=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "512aa280-be2c-4b63-8245-80390dfbbd2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DebertaV2Config {\n",
       "  \"_name_or_path\": \"microsoft/deberta-v3-large\",\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 1024,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 4096,\n",
       "  \"layer_norm_eps\": 1e-07,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"max_relative_positions\": -1,\n",
       "  \"model_type\": \"deberta-v2\",\n",
       "  \"norm_rel_ebd\": \"layer_norm\",\n",
       "  \"num_attention_heads\": 16,\n",
       "  \"num_hidden_layers\": 24,\n",
       "  \"output_hidden_states\": true,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"pooler_dropout\": 0,\n",
       "  \"pooler_hidden_act\": \"gelu\",\n",
       "  \"pooler_hidden_size\": 1024,\n",
       "  \"pos_att_type\": [\n",
       "    \"p2c\",\n",
       "    \"c2p\"\n",
       "  ],\n",
       "  \"position_biased_input\": false,\n",
       "  \"position_buckets\": 256,\n",
       "  \"relative_attention\": true,\n",
       "  \"share_att_key\": true,\n",
       "  \"transformers_version\": \"4.26.1\",\n",
       "  \"type_vocab_size\": 0,\n",
       "  \"vocab_size\": 128100\n",
       "}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f7a5996e-23d4-4d0a-ab28-75187db21b09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DebertaV2Config {\n",
       "  \"_name_or_path\": \"microsoft/deberta-v3-large\",\n",
       "  \"attention_dropout\": 0.0,\n",
       "  \"attention_probs_dropout_prob\": 0.0,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout\": 0.0,\n",
       "  \"hidden_dropout_prob\": 0.0,\n",
       "  \"hidden_size\": 1024,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 4096,\n",
       "  \"layer_norm_eps\": 1e-07,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"max_relative_positions\": -1,\n",
       "  \"model_type\": \"deberta-v2\",\n",
       "  \"norm_rel_ebd\": \"layer_norm\",\n",
       "  \"num_attention_heads\": 16,\n",
       "  \"num_hidden_layers\": 24,\n",
       "  \"output_hidden_states\": true,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"pooler_dropout\": 0,\n",
       "  \"pooler_hidden_act\": \"gelu\",\n",
       "  \"pooler_hidden_size\": 1024,\n",
       "  \"pos_att_type\": [\n",
       "    \"p2c\",\n",
       "    \"c2p\"\n",
       "  ],\n",
       "  \"position_biased_input\": false,\n",
       "  \"position_buckets\": 256,\n",
       "  \"relative_attention\": true,\n",
       "  \"share_att_key\": true,\n",
       "  \"transformers_version\": \"4.26.1\",\n",
       "  \"type_vocab_size\": 0,\n",
       "  \"vocab_size\": 128015\n",
       "}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9a894a20-7850-4fb4-b1ed-54a35a66f17b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.LayerNorm.bias', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.classifier.weight', 'mask_predictions.dense.weight', 'mask_predictions.dense.bias', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.bias']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "m3 = AutoModel.from_pretrained(\"microsoft/deberta-v3-large\", config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "47f591b2-52b8-4af9-94aa-6758f5115567",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "C:\\Users\\alcka\\anaconda3\\lib\\site-packages\\transformers\\convert_slow_tokenizer.py:446: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "t_ = AutoTokenizer.from_pretrained(\"microsoft/deberta-v3-large\", config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "378d3dea-183e-41dd-a547-068aa29fa8e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DebertaV2TokenizerFast(name_or_path='microsoft/deberta-v3-large', vocab_size=128000, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '[CLS]', 'eos_token': '[SEP]', 'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a3e7fa20-ab17-4283-bc98-afa98ff9d4ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128001"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(t_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec6d2bfd-9e54-4cdc-9f49-635d5c4d09cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.bias', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.dense.bias', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.dense.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.LayerNorm.weight']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "C:\\Users\\alcka\\anaconda3\\lib\\site-packages\\transformers\\convert_slow_tokenizer.py:446: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "m4 = AutoModel.from_pretrained(\"microsoft/deberta-v3-large\")\n",
    "t__ = AutoTokenizer.from_pretrained(\"microsoft/deberta-v3-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "926477ad-40d5-489f-9d97-6ca7914f47b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DebertaV2Config {\n",
       "  \"_name_or_path\": \"microsoft/deberta-v3-large\",\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 1024,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 4096,\n",
       "  \"layer_norm_eps\": 1e-07,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"max_relative_positions\": -1,\n",
       "  \"model_type\": \"deberta-v2\",\n",
       "  \"norm_rel_ebd\": \"layer_norm\",\n",
       "  \"num_attention_heads\": 16,\n",
       "  \"num_hidden_layers\": 24,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"pooler_dropout\": 0,\n",
       "  \"pooler_hidden_act\": \"gelu\",\n",
       "  \"pooler_hidden_size\": 1024,\n",
       "  \"pos_att_type\": [\n",
       "    \"p2c\",\n",
       "    \"c2p\"\n",
       "  ],\n",
       "  \"position_biased_input\": false,\n",
       "  \"position_buckets\": 256,\n",
       "  \"relative_attention\": true,\n",
       "  \"share_att_key\": true,\n",
       "  \"transformers_version\": \"4.26.1\",\n",
       "  \"type_vocab_size\": 0,\n",
       "  \"vocab_size\": 128100\n",
       "}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m4.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9da7f1d1-7e61-42ac-8a71-989db19da297",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DebertaV2TokenizerFast(name_or_path='microsoft/deberta-v3-large', vocab_size=128000, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '[CLS]', 'eos_token': '[SEP]', 'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "93f9aeb0-a172-463a-9926-ed2f2972c1ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128001"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(t__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8375779c-c9ce-47bf-a45d-9300479ad9b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t__.additional_special_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66578e28-1ca7-4c1a-bb89-97eef2b4aaed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[BR]',\n",
       " '[GENERIC_SCHOOL]',\n",
       " '[GENERIC_SCHOOL]',\n",
       " '[SCHOOL_NAME]',\n",
       " '[STUDENT_NAME]',\n",
       " '[GENERIC_NAME]',\n",
       " '[GENERIC_NAME]',\n",
       " '[GENERIC_CITY]',\n",
       " '[LOCATION_NAME]',\n",
       " '[HOTEL_NAME]',\n",
       " '[LANGUAGE_NAME]',\n",
       " '[PROPER_NAME]',\n",
       " '[OTHER_NAME]',\n",
       " '[PROPER_NAME]',\n",
       " '[RESTAURANT_NAME]',\n",
       " '[STORE_NAME]',\n",
       " '[TEACHER_NAME]']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.additional_special_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "630243be-7bd3-4599-bb47-2eb2cebe4f9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5fae657bff342f2b2e3870e8dcee31d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)ve/main/spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alcka\\anaconda3\\lib\\site-packages\\huggingface_hub\\file_download.py:129: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\alcka\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "241286d3681f42348ec638a2eac6c38a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)lve/main/config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alcka\\anaconda3\\lib\\site-packages\\transformers\\models\\t5\\tokenization_t5.py:163: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-small automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5Tokenizer\n",
    "\n",
    "tmp = T5Tokenizer.from_pretrained(\"t5-small\", extra_ids=0, additional_special_tokens=[\"new_token_1\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "550062d7-83b7-4290-bdc4-2b4369ff1594",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5Tokenizer(name_or_path='t5-small', vocab_size=32000, model_max_length=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'additional_special_tokens': ['new_token_1']})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "effc9340-8025-4728-bbce-98f0f3ab4b78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['new_token_1']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp.additional_special_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f2f03854-2084-4416-b184-adc0516af874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'new_token_1': 32000}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp.added_tokens_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e12d71ac-9d20-4335-8fcd-880c73d72887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['new_token_1']\n",
      "{'new_token_1': 32000}\n",
      "['â–this', 'â–is', 'â–', 'a', 'â–text', 'â–with', 'new_token_1', 'â–', ',', 'â–new', '_', 'to', 'ken', '_', '2', 'â–and', 'â–new', '_', 'to', 'ken', '_', '3', '</s>']\n",
      "***\n",
      "['new_token_2']\n",
      "{'new_token_1': 32000, 'new_token_2': 32001}\n",
      "['â–this', 'â–is', 'â–', 'a', 'â–text', 'â–with', 'new_token_1', 'â–', ',', 'new_token_2', 'â–and', 'â–new', '_', 'to', 'ken', '_', '3', '</s>']\n",
      "***\n",
      "['new_token_3']\n",
      "{'new_token_1': 32000, 'new_token_2': 32001, 'new_token_3': 32002}\n",
      "['â–this', 'â–is', 'â–', 'a', 'â–text', 'â–with', 'new_token_1', 'â–', ',', 'new_token_2', 'â–and', 'new_token_3', '</s>']\n"
     ]
    }
   ],
   "source": [
    "tokenizer = tmp\n",
    "text = \"this is a text with new_token_1, new_token_2 and new_token_3 \"\n",
    "\n",
    "print(tokenizer.additional_special_tokens)\n",
    "print(tokenizer.added_tokens_encoder)\n",
    "print(tokenizer.convert_ids_to_tokens(tokenizer.encode(text)))\n",
    "print(\"***\")\n",
    "\n",
    "tokenizer.add_special_tokens({\"additional_special_tokens\": [\"new_token_2\"]})\n",
    "print(tokenizer.additional_special_tokens)\n",
    "print(tokenizer.added_tokens_encoder)\n",
    "print(tokenizer.convert_ids_to_tokens(tokenizer.encode(text)))\n",
    "print(\"***\")\n",
    "\n",
    "tokenizer.add_special_tokens({\"additional_special_tokens\": [\"new_token_3\"]})\n",
    "print(tokenizer.additional_special_tokens)\n",
    "print(tokenizer.added_tokens_encoder)\n",
    "print(tokenizer.convert_ids_to_tokens(tokenizer.encode(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eff5780c-326a-4ac2-8302-ac5d0e28ffc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32003"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0473b437-a42d-4035-95e8-f0b2ff2711e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32000"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dc7cb60c-1630-4315-a8f9-12f2eb68bd30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['new_token_3']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.additional_special_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3f5a18ba-d735-47cf-bc06-8e3f773106ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'new_token_1': 32000, 'new_token_2': 32001, 'new_token_3': 32002}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.added_tokens_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a97112e-09fd-4183-9cb7-47b2c5f5c265",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python37",
   "language": "python",
   "name": "python37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

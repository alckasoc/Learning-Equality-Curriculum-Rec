{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25b12c4c-2e4a-486b-8a34-188e87e3eef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TOKENIZERS_PARALLELISM=true\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nvidia_smi\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.checkpoint import checkpoint\n",
    "import tokenizers\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
    "from transformers import get_cosine_schedule_with_warmup, DataCollatorWithPadding\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "%env TOKENIZERS_PARALLELISM=true\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89280ccd-a817-4157-ad31-29aa4726d11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom imports.\n",
    "from utils import f2_score, seed_everything, AverageMeter, timeSince, get_vram, get_param_counts\n",
    "from model_utils import MeanPooling\n",
    "from train_utils import get_model_fold_paths, save_best_models, select_optimizer, select_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df8074e9-0183-4c68-b4cf-b75b5ca66cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvincenttu\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18e3602b-9aaf-4014-9ec7-7a9e1c65f00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    print_freq = 500\n",
    "    num_workers = 4\n",
    "    model = \"xlm-roberta-base\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "    gradient_checkpointing = False\n",
    "    num_cycles = 0.5\n",
    "    warmup_ratio = 0.1\n",
    "    epochs = 5\n",
    "    encoder_lr = 1e-5\n",
    "    decoder_lr = 1e-4\n",
    "    eps = 1e-6\n",
    "    betas = (0.9, 0.999)\n",
    "    batch_size = 32\n",
    "    weight_decay = 0.01\n",
    "    max_grad_norm = 0.012\n",
    "    max_len = 512\n",
    "    n_folds = 5\n",
    "    seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5455ec7-4475-4797-86d6-1be58adcaabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(train):\n",
    "    train['title1'].fillna(\"Title does not exist\", inplace = True)\n",
    "    train['title2'].fillna(\"Title does not exist\", inplace = True)\n",
    "\n",
    "    # Create feature column\n",
    "    train['text'] = train['title1'] + '[SEP]' + train['title2']\n",
    "    \n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb0e8f02-7a00-4880-b51d-2c723dd7ed16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_split(train, cfg):\n",
    "    kfold = StratifiedGroupKFold(n_splits = cfg.n_folds, shuffle = True, random_state = cfg.seed)\n",
    "    for num, (train_index, val_index) in enumerate(kfold.split(train, train['target'], train['topics_ids'])):\n",
    "        train.loc[val_index, 'fold'] = int(num)\n",
    "    train['fold'] = train['fold'].astype(int)\n",
    "    \n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad99cf05-b3c6-4d2e-b70e-31b2cc171642",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_length(train, cfg):\n",
    "    lengths = []\n",
    "    for text in tqdm(train['text'].fillna(\"\").values, total = len(train)):\n",
    "        length = len(cfg.tokenizer(text, add_special_tokens = False)['input_ids'])\n",
    "        lengths.append(length)\n",
    "    cfg.max_len = max(lengths) + 2 # cls & sep\n",
    "    print(f\"max_len: {cfg.max_len}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38e8e47d-cbed-45d5-a9fb-84e51850f80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_input(text, cfg):\n",
    "    inputs = cfg.tokenizer.encode_plus(\n",
    "        text, \n",
    "        return_tensors = None, \n",
    "        add_special_tokens = True, \n",
    "        max_length = cfg.max_len,\n",
    "        pad_to_max_length = True,\n",
    "        truncation = True\n",
    "    )\n",
    "    for k, v in inputs.items():\n",
    "        inputs[k] = torch.tensor(v, dtype = torch.long)\n",
    "    return inputs\n",
    "\n",
    "class custom_dataset(Dataset):\n",
    "    def __init__(self, df, cfg):\n",
    "        self.cfg = cfg\n",
    "        self.texts = df['text'].values\n",
    "        self.labels = df['target'].values\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    def __getitem__(self, item):\n",
    "        inputs = prepare_input(self.texts[item], self.cfg)\n",
    "        label = torch.tensor(self.labels[item], dtype = torch.float)\n",
    "        return inputs, label\n",
    "    \n",
    "def collate(inputs):\n",
    "    mask_len = int(inputs[\"attention_mask\"].sum(axis=1).max())\n",
    "    for k, v in inputs.items():\n",
    "        inputs[k] = inputs[k][:,:mask_len]\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2af0f4bb-6c17-4367-84ab-5aba754d9a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class custom_model(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.config = AutoConfig.from_pretrained(cfg.model, output_hidden_states = True)\n",
    "        self.config.hidden_dropout = 0.0\n",
    "        self.config.hidden_dropout_prob = 0.0\n",
    "        self.config.attention_dropout = 0.0\n",
    "        self.config.attention_probs_dropout_prob = 0.0\n",
    "        self.model = AutoModel.from_pretrained(cfg.model, config = self.config)\n",
    "        if self.cfg.gradient_checkpointing:\n",
    "            self.model.gradient_checkpointing_enable()\n",
    "        self.pool = MeanPooling()\n",
    "        self.fc = nn.Linear(self.config.hidden_size, 1)\n",
    "        self._init_weights(self.fc)\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.padding_idx is not None:\n",
    "                module.weight.data[module.padding_idx].zero_()\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "    def feature(self, inputs):\n",
    "        outputs = self.model(**inputs)\n",
    "        last_hidden_state = outputs.last_hidden_state\n",
    "        feature = self.pool(last_hidden_state, inputs['attention_mask'])\n",
    "        return feature\n",
    "    def forward(self, inputs):\n",
    "        feature = self.feature(inputs)\n",
    "        output = self.fc(feature)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68fbb1b1-5b55-49a3-b71d-cafb3f65ff5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================================================\n",
    "# Train function loop\n",
    "# =========================================================================================\n",
    "def train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, device, cfg):\n",
    "    model.train()\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled = True)\n",
    "    losses = AverageMeter()\n",
    "    start = end = time.time()\n",
    "    global_step = 0\n",
    "    for step, (inputs, target) in enumerate(train_loader):\n",
    "        inputs = collate(inputs)\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = v.to(device)\n",
    "        target = target.to(device)\n",
    "        batch_size = target.size(0)\n",
    "        with torch.cuda.amp.autocast(enabled = True):\n",
    "            y_preds = model(inputs)\n",
    "            loss = criterion(y_preds.view(-1), target)\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.unscale_(optimizer)\n",
    "        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), cfg.max_grad_norm)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        optimizer.zero_grad()\n",
    "        global_step += 1\n",
    "        scheduler.step()\n",
    "        end = time.time()\n",
    "        if step % cfg.print_freq == 0 or step == (len(train_loader) - 1):\n",
    "            print('Epoch: [{0}][{1}/{2}] '\n",
    "                  'Elapsed {remain:s} '\n",
    "                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "                  'Grad: {grad_norm:.4f}  '\n",
    "                  'LR: {lr:.8f}  '\n",
    "                  .format(epoch + 1, \n",
    "                          step, \n",
    "                          len(train_loader), \n",
    "                          remain = timeSince(start, float(step + 1) / len(train_loader)),\n",
    "                          loss = losses,\n",
    "                          grad_norm = grad_norm,\n",
    "                          lr = scheduler.get_lr()[0]))\n",
    "            get_vram()\n",
    "\n",
    "    return losses.avg\n",
    "\n",
    "# =========================================================================================\n",
    "# Valid function loop\n",
    "# =========================================================================================\n",
    "def valid_fn(valid_loader, model, criterion, device, cfg):\n",
    "    losses = AverageMeter()\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    start = end = time.time()\n",
    "    for step, (inputs, target) in enumerate(valid_loader):\n",
    "        inputs = collate(inputs)\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = v.to(device)\n",
    "        target = target.to(device)\n",
    "        batch_size = target.size(0)\n",
    "        with torch.no_grad():\n",
    "            y_preds = model(inputs)\n",
    "        loss = criterion(y_preds.view(-1), target)\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        preds.append(y_preds.sigmoid().squeeze().to('cpu').numpy().reshape(-1))\n",
    "        end = time.time()\n",
    "        if step % cfg.print_freq == 0 or step == (len(valid_loader) - 1):\n",
    "            print('EVAL: [{0}/{1}] '\n",
    "                  'Elapsed {remain:s} '\n",
    "                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "                  .format(step, \n",
    "                          len(valid_loader),\n",
    "                          loss = losses,\n",
    "                          remain = timeSince(start, float(step + 1) / len(valid_loader))))\n",
    "            get_vram()\n",
    "            \n",
    "    predictions = np.concatenate(preds, axis = 0)\n",
    "    \n",
    "    return losses.avg, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64f6d8fe-6b15-444b-8822-d4110cf42a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_threshold(x_val, val_predictions, correlations):\n",
    "    best_score = 0\n",
    "    best_threshold = None\n",
    "    for thres in np.arange(0.001, 0.1, 0.001):\n",
    "        x_val['predictions'] = np.where(val_predictions > thres, 1, 0)\n",
    "        x_val1 = x_val[x_val['predictions'] == 1]\n",
    "        x_val1 = x_val1.groupby(['topics_ids'])['content_ids'].unique().reset_index()\n",
    "        x_val1['content_ids'] = x_val1['content_ids'].apply(lambda x: ' '.join(x))\n",
    "        x_val1.columns = ['topic_id', 'predictions']\n",
    "        x_val0 = pd.Series(x_val['topics_ids'].unique())\n",
    "        x_val0 = x_val0[~x_val0.isin(x_val1['topic_id'])]\n",
    "        x_val0 = pd.DataFrame({'topic_id': x_val0.values, 'predictions': \"\"})\n",
    "        x_val_r = pd.concat([x_val1, x_val0], axis = 0, ignore_index = True)\n",
    "        x_val_r = x_val_r.merge(correlations, how = 'left', on = 'topic_id')\n",
    "        score = f2_score(x_val_r['content_ids'], x_val_r['predictions'])\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_threshold = thres\n",
    "    return best_score, best_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6703bc5b-0a01-461a-971d-9ebc73f7f8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer_params(model, encoder_lr, decoder_lr, weight_decay = 0.0):\n",
    "    no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "    optimizer_parameters = [\n",
    "        {'params': [p for n, p in model.model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "        'lr': encoder_lr, 'weight_decay': weight_decay},\n",
    "        {'params': [p for n, p in model.model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "        'lr': encoder_lr, 'weight_decay': 0.0},\n",
    "        {'params': [p for n, p in model.named_parameters() if \"model\" not in n],\n",
    "        'lr': decoder_lr, 'weight_decay': 0.0}\n",
    "    ]\n",
    "    return optimizer_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf5a3b87-20d1-4647-81d9-e95be33e8727",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd13b808edac4964a51e95a7eaae8fa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/615170 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_len: 172\n"
     ]
    }
   ],
   "source": [
    "# Seed everything\n",
    "seed_everything(CFG)\n",
    "\n",
    "# Read data\n",
    "correlations = pd.read_csv(\"../input/correlations.csv\")\n",
    "train = read_data(pd.read_csv(\"../input/train.csv\"))\n",
    "\n",
    "# Split data\n",
    "cv_split(train, CFG)\n",
    "\n",
    "# Get max length\n",
    "get_max_length(train, CFG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3c79859-fa99-4ec8-932d-619cb93aec51",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = 0\n",
    "cfg = CFG()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d91c950d-0b5d-4235-9586-88a25464fc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train & validation\n",
    "x_train = train[train['fold'] != fold]\n",
    "x_val = train[train['fold'] == fold]\n",
    "valid_labels = x_val['target'].values\n",
    "train_dataset = custom_dataset(x_train, cfg)\n",
    "valid_dataset = custom_dataset(x_val, cfg)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size = cfg.batch_size, \n",
    "    shuffle = True, \n",
    "    num_workers = cfg.num_workers, \n",
    "    pin_memory = True, \n",
    "    drop_last = True\n",
    ")\n",
    "valid_loader = DataLoader(\n",
    "    valid_dataset, \n",
    "    batch_size = cfg.batch_size, \n",
    "    shuffle = False, \n",
    "    num_workers = cfg.num_workers, \n",
    "    pin_memory = True, \n",
    "    drop_last = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "24a0f66d-1e21-412a-8689-4d3f6f55aa5f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Get model\n",
    "model = custom_model(cfg)\n",
    "_ = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a07c721-ac78-47c8-8017-1c7b7973491d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_parameters = get_optimizer_params(\n",
    "    model, \n",
    "    encoder_lr = cfg.encoder_lr, \n",
    "    decoder_lr = cfg.decoder_lr,\n",
    "    weight_decay = cfg.weight_decay\n",
    ")\n",
    "optimizer = AdamW(\n",
    "    optimizer_parameters, \n",
    "    lr = cfg.encoder_lr, \n",
    "    eps = cfg.eps, \n",
    "    betas = cfg.betas\n",
    ")\n",
    "\n",
    "# Scheduler\n",
    "num_train_steps = int(len(x_train) / cfg.batch_size * cfg.epochs)\n",
    "num_warmup_steps = num_train_steps * cfg.warmup_ratio\n",
    "scheduler = get_cosine_schedule_with_warmup(\n",
    "    optimizer, \n",
    "    num_warmup_steps = num_warmup_steps, \n",
    "    num_training_steps = num_train_steps, \n",
    "    num_cycles = cfg.num_cycles\n",
    "    )\n",
    "\n",
    "# Criterion\n",
    "criterion = nn.BCEWithLogitsLoss(reduction = \"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4f4893e5-ba91-47a9-9b2c-54e960e082cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing GPU stats...\n",
      "Device 0: b'NVIDIA A40', Memory : (81.13% free): 17.995312768034637 (total), 14.598828393034637 (free), 3.396484375 (used)\n"
     ]
    }
   ],
   "source": [
    "print(\"Printing GPU stats...\")\n",
    "get_vram()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b9dec669-3f7c-41b6-8edc-36c3a7e2588b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.13.7 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/vincenttu/LECR_0.297_baseline/runs/3vebzwk1\" target=\"_blank\">fold0</a></strong> to <a href=\"https://wandb.ai/vincenttu/LECR_0.297_baseline\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "project = \"LECR_0.297_baseline\"\n",
    "cfg_params = [i for i in dir(cfg) if \"__\" not in i]\n",
    "cfg_params = dict(zip(cfg_params, [getattr(cfg, i) for i in cfg_params]))\n",
    "total_params, trainable_params, nontrainable_params = get_param_counts(model)\n",
    "cfg_params.update({\n",
    "    \"total_params\": total_params,\n",
    "    \"trainable_params\": trainable_params,\n",
    "    \"nontrainable_params\": nontrainable_params\n",
    "})\n",
    "\n",
    "save_root = \"../models/0297_baseline/\"\n",
    "os.makedirs(save_root, exist_ok=True)\n",
    "\n",
    "run = wandb.init(project=project, config=cfg_params, name=f\"fold{fold}\", dir=\"/tmp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2112c590-f1bf-4439-bb73-6ebeb15f3904",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/15381] Elapsed 0m 0s (remain 119m 58s) Loss: 0.8532(0.8532) Grad: inf  LR: 0.00000000  \n",
      "Device 0: b'NVIDIA A40', Memory : (71.05% free): 17.995312768034637 (total), 12.786328393034637 (free), 5.208984375 (used)\n",
      "Epoch: [1][500/15381] Elapsed 0m 46s (remain 22m 53s) Loss: 0.5878(0.7907) Grad: 6.3956  LR: 0.00000065  \n",
      "Device 0: b'NVIDIA A40', Memory : (53.26% free): 17.995312768034637 (total), 9.585156518034637 (free), 8.41015625 (used)\n",
      "Epoch: [1][1000/15381] Elapsed 1m 32s (remain 22m 3s) Loss: 0.2023(0.5462) Grad: 4.6545  LR: 0.00000130  \n",
      "Device 0: b'NVIDIA A40', Memory : (52.92% free): 17.995312768034637 (total), 9.522656518034637 (free), 8.47265625 (used)\n",
      "Epoch: [1][1500/15381] Elapsed 2m 18s (remain 21m 19s) Loss: 0.1050(0.4402) Grad: 9.4569  LR: 0.00000195  \n",
      "Device 0: b'NVIDIA A40', Memory : (52.81% free): 17.995312768034637 (total), 9.503125268034637 (free), 8.4921875 (used)\n",
      "Epoch: [1][2000/15381] Elapsed 3m 4s (remain 20m 32s) Loss: 0.2976(0.3828) Grad: 7.6789  LR: 0.00000260  \n",
      "Device 0: b'NVIDIA A40', Memory : (51.12% free): 17.995312768034637 (total), 9.198437768034637 (free), 8.796875 (used)\n",
      "Epoch: [1][2500/15381] Elapsed 3m 50s (remain 19m 46s) Loss: 0.2006(0.3475) Grad: 8.0548  LR: 0.00000325  \n",
      "Device 0: b'NVIDIA A40', Memory : (48.71% free): 17.995312768034637 (total), 8.764844018034637 (free), 9.23046875 (used)\n",
      "Epoch: [1][3000/15381] Elapsed 4m 36s (remain 19m 0s) Loss: 0.1220(0.3217) Grad: 6.9719  LR: 0.00000390  \n",
      "Device 0: b'NVIDIA A40', Memory : (48.71% free): 17.995312768034637 (total), 8.764844018034637 (free), 9.23046875 (used)\n",
      "Epoch: [1][3500/15381] Elapsed 5m 22s (remain 18m 13s) Loss: 0.1017(0.3022) Grad: 9.0300  LR: 0.00000455  \n",
      "Device 0: b'NVIDIA A40', Memory : (48.71% free): 17.995312768034637 (total), 8.764844018034637 (free), 9.23046875 (used)\n",
      "Epoch: [1][4000/15381] Elapsed 6m 8s (remain 17m 26s) Loss: 0.2990(0.2867) Grad: 10.6373  LR: 0.00000520  \n",
      "Device 0: b'NVIDIA A40', Memory : (48.71% free): 17.995312768034637 (total), 8.764844018034637 (free), 9.23046875 (used)\n"
     ]
    }
   ],
   "source": [
    "best_score = 0\n",
    "for epoch in range(cfg.epochs):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Train\n",
    "    avg_loss = train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, device, cfg)\n",
    "    \n",
    "    # Validation\n",
    "    avg_val_loss, predictions = valid_fn(valid_loader, model, criterion, device, cfg)\n",
    "    \n",
    "    # Compute f2_score\n",
    "    score, threshold = get_best_threshold(x_val, predictions, correlations)\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    \n",
    "    print(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n",
    "    print(f'Epoch {epoch+1} - Score: {score:.4f} - Threshold: {threshold:.5f}')\n",
    "    \n",
    "    run.log({\n",
    "        \"epoch\": epoch,\n",
    "        \"avg_train_loss\": avg_loss,\n",
    "        \"avg_val_loss\": avg_val_loss,\n",
    "        \"f2_score\": score,\n",
    "        \"threshold\": threshold\n",
    "    })\n",
    "    \n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        print(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n",
    "        save_p = os.path.join(save_root, f\"{cfg.model.replace('/', '-')}_fold{fold}_ep{epoch}.pth\")\n",
    "        torch.save(model.state_dict(), save_p)\n",
    "        # torch.save(\n",
    "        #     {'model': model.state_dict(), 'predictions': predictions}, \n",
    "        #     f\"{cfg.model.replace('/', '-')}_fold{fold}_{cfg.seed}.pth\"\n",
    "        #     )\n",
    "        val_predictions = predictions\n",
    "        \n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "# Get best threshold\n",
    "best_score, best_threshold = get_best_threshold(x_val, val_predictions, correlations)\n",
    "print(f'Our CV score is {best_score} using a threshold of {best_threshold}')\n",
    "\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "28c9283b-0ad9-4366-a8f4-bf7b95b1afd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 285... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "</div><div class=\"wandb-col\">\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">fold0</strong>: <a href=\"https://wandb.ai/vincenttu/LECR_0.297_baseline/runs/wozwt51l\" target=\"_blank\">https://wandb.ai/vincenttu/LECR_0.297_baseline/runs/wozwt51l</a><br/>\n",
       "Find logs at: <code>/tmp/wandb/run-20230108_022212-wozwt51l/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c29c904-3c45-4776-b785-8cecac4c8c8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python37",
   "language": "python",
   "name": "python37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(train_context):\n",
    "    \n",
    "    curr_text_cols = [\n",
    "         \"topic_title\", \n",
    "         \"topic_description\", \n",
    "         \"content_title\", \n",
    "         \"content_description\", \n",
    "         \"content_text\"\n",
    "    ]\n",
    "    \n",
    "    context_text_cols = [\n",
    "        \"topic_parent_title\", \n",
    "        \"topic_parent_description\", \n",
    "        \"topic_child_title\", \n",
    "        \"topic_child_description\"\n",
    "    ]\n",
    "\n",
    "    train_context = deepcopy(train_context)\n",
    "    \n",
    "    # Replace uninformative/duplicate titles/descriptions with nothing.\n",
    "    \n",
    "    def useless_desc(x):\n",
    "        # remove 1 letter descriptions, and improve descriptions with links\n",
    "            words = re.sub(r\"source_url=\", \"\", x)\n",
    "            words = x.split()\n",
    "            match = re.search(r\"http[s]?://(www\\.)?([\\w-]+).org/([\\w-]+)/([\\w-]+)/([\\w-]+)\\.(mp4)\", words)\n",
    "            unwanted = [\"Additional resources and links.\", \"Test your knowledge.\",\"Entire lesson\", \"Teacher's Guide English version\", \"Test your knowledge!\", \"Written Transcript of this video lesson\", \"Read Teacher's Guide to this video lesson\", \"Written Transcript of this video lesson in English\", \"Written Transcript of this video lesson in Arabic\", \"Teacher's Guide Arabic version\", \"Abonnez vous pour recevoir nos nouveaux cours GRATUITS en HD\", \"Download Written Transcript of this video lesson\"]\n",
    "            if match:\n",
    "                return match.group(2)+\" \"+match.group(4)+\" \"+match.group(5)\n",
    "            \n",
    "            elif (len(words) <= 1) or words in unwanted:\n",
    "                return ''\n",
    "            return x\n",
    "        \n",
    "    for col in (curr_text_cols + context_text_cols):\n",
    "        if \"description\" in col:\n",
    "                train_context[col] = train_context[col].apply(useless_desc)\n",
    "    \n",
    "    # def duplicate_titles(x):\n",
    "    #     for col in (curr_text_cols + context_text_cols):\n",
    "    #         if \"title\" in col:\n",
    "    \n",
    "    # Remove stopwords for all languages.\n",
    "    from nltk.tokenize import word_tokenize\n",
    "    \n",
    "    stop_words_en = set(stopwords.words('english'))\n",
    "    stop_words_es = set(stopwords.words('spanish'))\n",
    "    stop_words_fr = set(stopwords.words('french'))\n",
    "    stop_words_ar = set(stopwords.words('arabic'))\n",
    "    stop_words_pt = set(stopwords.words('portuguese'))\n",
    "\n",
    "    stop_words_all = set.union(stop_words_en, stop_words_es, stop_words_fr, stop_words_ar, stop_words_pt)\n",
    "\n",
    "    def remove_stopwords(x):\n",
    "        words = word_tokenize(x)\n",
    "        x = [word for word in words if word.lower() not in stop_words_all]\n",
    "        return x\n",
    "    \n",
    "    # Handle \"source_id=\" in topic descriptions.\n",
    "    def replace_sourceid(x):\n",
    "        if x is not np.nan:\n",
    "            if \"source_id\" in x:\n",
    "                x = \"\"\n",
    "        return x\n",
    "    \n",
    "    for col in (curr_text_cols + context_text_cols):\n",
    "        if \"description\" in col:\n",
    "            train_context[col] = train_context[col].apply(replace_sourceid)\n",
    "    \n",
    "    # Handle literal gibberish: '5ad59f7a6b9064043e263f03' and weird links (YouTube link).\n",
    "    def remove_gibberish(x):\n",
    "        return re.sub(r'\\b\\w{20,}\\b', '', x)\n",
    "    \n",
    "    def link_shortener(x):\n",
    "        return re.sub(r'https?:\\/\\/(www\\.)?([a-zA-Z0-9]+\\.[a-zA-Z]{2,3})(\\/\\S*)?', r'\\2', x)\n",
    "    \n",
    "    # Handle Topic, Section, Chapter text.\n",
    "    \n",
    "    # Remove numbers.\n",
    "    def remove_numbers(x):\n",
    "        if x is np.nan:\n",
    "            return x\n",
    "        return re.sub(\" \\d+\", \"\", x)\n",
    "    \n",
    "    # Remove special characters.\n",
    "    def remove_chars(x, include_brackets=False):\n",
    "        if x is np.nan:\n",
    "            return x\n",
    "        if include_brackets:\n",
    "            return x.translate(str.maketrans('', '', string.punctuation.replace(\"[\", \"\").replace(\"]\", \"\")))\n",
    "        return x.translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    print(\"Removing special characters & numbers...\")\n",
    "    for col in tqdm(curr_text_cols, position=0, leave=True, total=len(curr_text_cols)):\n",
    "        train_context[col] = train_context[col].apply(remove_chars)\n",
    "        train_context[col] = train_context[col].apply(remove_numbers)\n",
    "        \n",
    "    for col in tqdm(context_text_cols, position=0, leave=True, total=len(context_text_cols)):\n",
    "        train_context[col] = train_context[col].apply(remove_chars, include_brackets=True)\n",
    "        train_context[col] = train_context[col].apply(remove_numbers)\n",
    "\n",
    "    \n",
    "\n",
    "    print(\"Finished\")\n",
    "    \n",
    "    # Remove leading or trailing whitespace.\n",
    "    \n",
    "    \n",
    "    return train_context"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "fdcc3e2eda9bc7676fcc874e9c9a93d9b3ee4a15c7e9fc40c33a096bd1f91a00"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

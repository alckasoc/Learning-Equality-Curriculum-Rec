<<<<<<< HEAD
{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Examples of validation methods correlated with Public Score\n\nThe content of train could be the answer to test, but there is content in test that is not connected to train at all.\nTherefore, I have split the content in such a way that the content that is only connected to test is not used in the training.\n(All contents are used during inference).\n\n> The full test set includes an additional 10,000 topics (none present in the training set) and a large number of additional content items. The additional content items are only correlated to test set topics.\n\nMore information is available in [Discussion](https://www.kaggle.com/competitions/learning-equality-curriculum-recommendations/discussion/372875)","metadata":{}},{"cell_type":"code","source":"from pathlib import Path\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import StratifiedGroupKFold\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn.pipeline import Pipeline\nfrom cuml import NearestNeighbors","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-12-19T01:48:57.628519Z","iopub.execute_input":"2022-12-19T01:48:57.628942Z","iopub.status.idle":"2022-12-19T01:48:57.635323Z","shell.execute_reply.started":"2022-12-19T01:48:57.628889Z","shell.execute_reply":"2022-12-19T01:48:57.634303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"INPUT_DIR = Path('/kaggle/input/learning-equality-curriculum-recommendations')\nN_SPLITS = 6\nN_NEIGHBORS_LIST = [1, 2, 3, 8, 12]\nN_COMPONENTS = 128","metadata":{"execution":{"iopub.status.busy":"2022-12-19T01:51:48.032653Z","iopub.execute_input":"2022-12-19T01:51:48.033042Z","iopub.status.idle":"2022-12-19T01:51:48.03935Z","shell.execute_reply.started":"2022-12-19T01:51:48.033008Z","shell.execute_reply":"2022-12-19T01:51:48.038171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"topic_df = pd.read_csv(INPUT_DIR / 'topics.csv')\ncontent_df = pd.read_csv(INPUT_DIR / 'content.csv')\ncorr_df = pd.read_csv(INPUT_DIR / 'correlations.csv')\ntopic_df = topic_df.merge(\n    corr_df, left_on='id', right_on='topic_id', how='left'\n)\ntopic_df = topic_df.drop(columns=['topic_id'])","metadata":{"execution":{"iopub.status.busy":"2022-12-19T01:51:48.838187Z","iopub.execute_input":"2022-12-19T01:51:48.838546Z","iopub.status.idle":"2022-12-19T01:52:00.893756Z","shell.execute_reply.started":"2022-12-19T01:51:48.838514Z","shell.execute_reply":"2022-12-19T01:52:00.892612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Split","metadata":{}},{"cell_type":"code","source":"topic_df['stratify_category'] = (\n    topic_df['category'] != 'source' + '_' +\n    topic_df['description'].notnull().astype(str)\n#     topic_df['has_content'].astype(str)\n)","metadata":{"execution":{"iopub.status.busy":"2022-12-19T01:52:46.428292Z","iopub.execute_input":"2022-12-19T01:52:46.428646Z","iopub.status.idle":"2022-12-19T01:52:46.496467Z","shell.execute_reply.started":"2022-12-19T01:52:46.428612Z","shell.execute_reply":"2022-12-19T01:52:46.495479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kf = StratifiedGroupKFold(n_splits=N_SPLITS, shuffle=True, random_state=42)\nfolds = list(kf.split(topic_df, topic_df['stratify_category'], groups=topic_df[\"channel\"]))\ntopic_df['fold'] = np.nan\ncontent_df['fold'] = np.nan\n\nfor fold, (train_idx, val_idx) in enumerate(folds):\n    topic_df.loc[val_idx, \"fold\"] = fold\n    train_topic_df = topic_df.query(f\"fold != {fold}\").reset_index(drop=True)\n    val_topic_df = topic_df.query(f\"fold == {fold}\").reset_index(drop=True)\n\n    train_content_ids = set(train_topic_df[\"content_ids\"].str.split().explode().to_list())\n    val_content_ids = set(val_topic_df[\"content_ids\"].str.split().explode().to_list())\n    only_val_content_ids = val_content_ids - train_content_ids\n    content_df.loc[content_df['id'].isin(only_val_content_ids), 'fold'] = fold","metadata":{"execution":{"iopub.status.busy":"2022-12-19T01:53:11.477746Z","iopub.execute_input":"2022-12-19T01:53:11.478478Z","iopub.status.idle":"2022-12-19T01:53:13.514288Z","shell.execute_reply.started":"2022-12-19T01:53:11.478437Z","shell.execute_reply":"2022-12-19T01:53:13.513266Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display(topic_df['fold'].value_counts())","metadata":{"execution":{"iopub.status.busy":"2022-12-19T01:55:01.480198Z","iopub.execute_input":"2022-12-19T01:55:01.481199Z","iopub.status.idle":"2022-12-19T01:55:01.492635Z","shell.execute_reply.started":"2022-12-19T01:55:01.48116Z","shell.execute_reply":"2022-12-19T01:55:01.49141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Cross Validation","metadata":{}},{"cell_type":"code","source":"# ref: https://www.kaggle.com/code/columbia2131/lecr-example-of-f2-score\ndef fbeta_score(y_true_ids: pd.Series, y_pred_ids: pd.Series, beta=2, eps=1e-15):\n    true_ids = y_true_ids.str.split()\n    pred_ids = y_pred_ids.str.split()\n    score_list = []\n    for true, pred in zip(true_ids.tolist(), pred_ids.tolist()):\n        TP = (set(true) & set(pred))\n        precision = len(TP) / len(pred)\n        recall = len(TP) / len(true)\n        f2 = (1+beta**2) * (precision*recall) / ((beta**2)*precision+recall+eps)\n        score_list.append(f2)\n    score = sum(score_list) / len(score_list)\n    return score","metadata":{"execution":{"iopub.status.busy":"2022-12-19T01:53:16.126889Z","iopub.execute_input":"2022-12-19T01:53:16.12761Z","iopub.status.idle":"2022-12-19T01:53:16.134802Z","shell.execute_reply.started":"2022-12-19T01:53:16.12757Z","shell.execute_reply":"2022-12-19T01:53:16.133836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for fold in range(N_SPLITS):\n    val_topic_df = topic_df.query(f\"fold == {fold}\").reset_index(drop=True)\n    train_content_df = content_df.query(f\"fold != {fold}\").reset_index(drop=True)\n\n    # embedding\n    tfidf_svd = Pipeline([\n        (\"tfidf\", TfidfVectorizer()),\n        (\"svd\", TruncatedSVD(n_components=N_COMPONENTS))\n    ])\n    tfidf_svd.fit(train_content_df[\"title\"].fillna(''))\n    val_content_vec = tfidf_svd.transform(content_df[\"title\"].fillna(''))\n    val_topic_vec = tfidf_svd.transform(val_topic_df[\"title\"].fillna(''))\n\n    # candidate\n    nn = NearestNeighbors(n_neighbors=max(N_NEIGHBORS_LIST))\n    nn.fit(val_content_vec)\n    _, indices = nn.kneighbors(val_topic_vec)\n    \n    for n_neighbors in N_NEIGHBORS_LIST:\n        # prediction\n        preds = pd.Series(content_df[\"id\"].values[indices[:, :n_neighbors]].tolist())\n        preds = preds.apply(lambda x: \" \".join(x))\n        topic_df.loc[topic_df['fold']==fold, f'pred_content_ids_{n_neighbors}'] = preds.values\n\n        # evaluation\n        targets = val_topic_df['content_ids']\n        has_content = val_topic_df['has_content']\n        valid_category = (\n        (val_topic_df['category'] == 'aligned').astype(bool) |\n        (val_topic_df['category'] == 'supplemental').astype(bool)\n        )\n        valid_mask = has_content & valid_category\n        score = fbeta_score(targets[valid_mask], preds[valid_mask])\n        print(f'fold {fold}: {score:.4f}, n_neighbors={n_neighbors}')\n    print('----------------------------------------')\n\n# whole score\nfor n_neighbors in N_NEIGHBORS_LIST:\n    preds = topic_df[f'pred_content_ids_{n_neighbors}']\n    targets = topic_df['content_ids']\n    has_content = topic_df['has_content']\n    valid_category = (\n        (topic_df['category'] == 'aligned').astype(bool) |\n        (topic_df['category'] == 'supplemental').astype(bool)\n    )\n    valid_mask = has_content & valid_category\n    score = fbeta_score(targets[valid_mask], preds[valid_mask])\n    print(f'whole score : {score:.4f}, n_neighbor={n_neighbors}')","metadata":{"execution":{"iopub.status.busy":"2022-12-19T01:53:17.132167Z","iopub.execute_input":"2022-12-19T01:53:17.132572Z","iopub.status.idle":"2022-12-19T01:54:58.82213Z","shell.execute_reply.started":"2022-12-19T01:53:17.132531Z","shell.execute_reply":"2022-12-19T01:54:58.820972Z"},"trusted":true},"execution_count":null,"outputs":[]}]}
=======
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples of validation methods correlated with Public Score\n",
    "\n",
    "The content of train could be the answer to test, but there is content in test that is not connected to train at all.\n",
    "Therefore, I have split the content in such a way that the content that is only connected to test is not used in the training.\n",
    "(All contents are used during inference).\n",
    "\n",
    "> The full test set includes an additional 10,000 topics (none present in the training set) and a large number of additional content items. The additional content items are only correlated to test set topics.\n",
    "\n",
    "More information is available in [Discussion](https://www.kaggle.com/competitions/learning-equality-curriculum-recommendations/discussion/372875)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import Pipeline\n",
    "# from cuml import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "INPUT_DIR = Path('../../input/')\n",
    "N_SPLITS = 6\n",
    "N_NEIGHBORS_LIST = [1, 2, 3, 8, 12]\n",
    "N_COMPONENTS = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "topic_df = pd.read_csv(INPUT_DIR / 'topics.csv')\n",
    "content_df = pd.read_csv(INPUT_DIR / 'content.csv')\n",
    "corr_df = pd.read_csv(INPUT_DIR / 'correlations.csv')\n",
    "topic_df = topic_df.merge(\n",
    "    corr_df, left_on='id', right_on='topic_id', how='left'\n",
    ")\n",
    "topic_df = topic_df.drop(columns=['topic_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "topic_df['stratify_category'] = (\n",
    "    topic_df['category'] != 'source' + '_' +\n",
    "    topic_df['description'].notnull().astype(str)\n",
    "#     topic_df['has_content'].astype(str)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "kf = StratifiedGroupKFold(n_splits=N_SPLITS, shuffle=True, random_state=42)\n",
    "folds = list(kf.split(topic_df, topic_df['stratify_category'], groups=topic_df[\"channel\"]))\n",
    "topic_df['fold'] = np.nan\n",
    "content_df['fold'] = np.nan\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(folds):\n",
    "    topic_df.loc[val_idx, \"fold\"] = fold\n",
    "    train_topic_df = topic_df.query(f\"fold != {fold}\").reset_index(drop=True)\n",
    "    val_topic_df = topic_df.query(f\"fold == {fold}\").reset_index(drop=True)\n",
    "\n",
    "    train_content_ids = set(train_topic_df[\"content_ids\"].str.split().explode().to_list())\n",
    "    val_content_ids = set(val_topic_df[\"content_ids\"].str.split().explode().to_list())\n",
    "    only_val_content_ids = val_content_ids - train_content_ids\n",
    "    content_df.loc[content_df['id'].isin(only_val_content_ids), 'fold'] = fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0    15133\n",
       "1.0    14599\n",
       "0.0    14348\n",
       "4.0    13072\n",
       "2.0    11126\n",
       "5.0     8694\n",
       "Name: fold, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(topic_df['fold'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0    29161\n",
       "3.0    27354\n",
       "NaN    25292\n",
       "1.0    20403\n",
       "0.0    19446\n",
       "5.0    17532\n",
       "2.0    14859\n",
       "Name: fold, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_df.fold.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0    15133\n",
       "1.0    14599\n",
       "0.0    14348\n",
       "4.0    13072\n",
       "2.0    11126\n",
       "5.0     8694\n",
       "Name: fold, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_df.fold.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0.0\n",
       "1        4.0\n",
       "2        4.0\n",
       "3        5.0\n",
       "4        0.0\n",
       "        ... \n",
       "76967    5.0\n",
       "76968    2.0\n",
       "76969    1.0\n",
       "76970    4.0\n",
       "76971    1.0\n",
       "Name: fold, Length: 76972, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_df.fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         NaN\n",
       "1         5.0\n",
       "2         3.0\n",
       "3         1.0\n",
       "4         2.0\n",
       "         ... \n",
       "154042    3.0\n",
       "154043    5.0\n",
       "154044    4.0\n",
       "154045    4.0\n",
       "154046    0.0\n",
       "Name: fold, Length: 154047, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_df.fold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining with train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../../input/train_context.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.merge(topic_df[[\"id\", \"channel\", \"category\", \"language\", \"fold\"]], how=\"left\", left_on=\"topics_ids\", right_on=\"id\").drop(columns=[\"id\"])\n",
    "train = train.rename(columns={\"fold\": \"topic_fold\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(615170, 16)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.merge(content_df[[\"id\", \"kind\", \"language\", \"fold\"]], how=\"left\", left_on=\"content_ids\", right_on=\"id\").drop(columns=[\"id\"])\n",
    "train = train.rename(columns={\"fold\": \"content_fold\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.rename(columns={\"category\": \"topic_category\", \n",
    "                              \"language_x\": \"topic_language\", \n",
    "                              \"kind\": \"content_kind\",\n",
    "                              \"language_y\": \"content_language\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['topics_ids', 'content_ids', 'topic_title', 'topic_description',\n",
       "       'content_title', 'content_description', 'content_text',\n",
       "       'topic_parent_title', 'topic_parent_description', 'topic_child_title',\n",
       "       'topic_child_description', 'target', 'channel', 'topic_category',\n",
       "       'topic_language', 'topic_fold', 'content_kind', 'content_language',\n",
       "       'content_fold'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cols = [\n",
    "    'topics_ids', 'content_ids', 'channel', 'topic_title', 'topic_description', \n",
    "    'topic_parent_title', 'topic_parent_description', 'topic_child_title', 'topic_child_description',\n",
    "    'topic_category', 'topic_language',\n",
    "    'content_title', 'content_description', 'content_text',\n",
    "    'content_kind', 'content_language', \n",
    "    'target',\n",
    "    'topic_fold', 'content_fold'\n",
    "]\n",
    "assert len(set(new_cols)) == len(set(train.columns))\n",
    "\n",
    "train = train.loc[:, new_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(\"../../input/train_context_5fold.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
>>>>>>> 714ce1f17d1c784b6804f92e486b2e02c623cf74
